name: big-data-hust-project
services:
  broker:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: broker
    user: root
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@broker:29093"
      KAFKA_LISTENERS: "PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092"
      KAFKA_INTER_BROKER_LISTENER_NAME: "PLAINTEXT"
      KAFKA_CONTROLLER_LISTENER_NAMES: "CONTROLLER"
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"

  spark-master:
    container_name: hust-spark-master
    hostname: spark-master
    build: .
    image: hust-spark-image
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    volumes:
      - ./spark/data:/opt/spark/data
      - ./spark/spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
      - ./entrypoint.sh:/entrypoint.sh
      - ./models:/opt/spark/models
    entrypoint: ["./entrypoint.sh", "master"]
    env_file:
      - .env.spark
    ports:
      - "9090:8080"
      - "7077:7077"

  spark-history-server:
    container_name: hust-spark-history
    image: hust-spark-image
    entrypoint: ["./entrypoint.sh", "history"]
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - spark-logs:/opt/spark/spark-events
      - ./entrypoint.sh:/entrypoint.sh
    ports:
      - "18080:18080"

  spark-worker:
    image: hust-spark-image
    entrypoint: ["./entrypoint.sh", "worker"]
    depends_on:
      - spark-master
    env_file:
      - .env.spark
    volumes:
      - ./spark/data:/opt/spark/data
      - ./spark/spark_apps:/opt/spark/apps
      - spark-logs:/opt/spark/spark-events
      - ./entrypoint.sh:/entrypoint.sh

  mongodb:
    image: mongo:latest
    container_name: mongodb
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root
      MONGO_INITDB_ROOT_PASSWORD: admin

  grafana:
    image: grafana/grafana-oss:8.4.3
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
    depends_on:
      - mongodb

  influxdb:
    image: bitnami/influxdb:2.5.1
    container_name: influxdb
    restart: always
    ports:
      - 8086:8086
    volumes:
      - .\influxdb:/bitnami/influxdb
    environment:
      INFLUXDB_ADMIN_USER_PASSWORD: ${INFLUXDB_ADMIN_USER_PASSWORD}
      INFLUXDB_USER: ${INFLUXDB_USER}
      INFLUXDB_USER_PASSWORD: ${INFLUXDB_USER_PASSWORD}
      INFLUXDB_ADMIN_USER_TOKEN: ${INFLUX_TOKEN}
      INFLUXDB_DB: ${INFLUXDB_DB} # the database to be created on first startup
      INFLUXDB_HTTP_AUTH_ENABLED: true # enable http auth
      INFLUX_TOKEN: ${INFLUX_TOKEN}
      # INFLUXDB_BUCKET: ${INFLUXDB_DB}
      # INFLUXDB_BUCKET: ${INFLUXDB_PLAYER_BUCKET}
      # INFLUXDB_BUCKET: ${INFLUXDB_CARD_BUCKET}
      INFLUX_ORG: ${INFLUX_ORG}
      INFLUXDB_MEASUREMENT: ${INFLUXDB_MEASUREMENT}

  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongodb
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: admin
      ME_CONFIG_MONGODB_URL: mongodb://root:admin@mongodb:27017
      ME_CONFIG_BASICAUTH_USERNAME: root
      ME_CONFIG_BASICAUTH_PASSWORD: admin
    depends_on:
      - mongodb

  recommendation-api:
    build:
      context: .
      dockerfile: Dockerfile.api
    container_name: recommendation-api
    image: recommendation-api
    restart: unless-stopped
    environment:
      - MONGO_HOST=mongodb
      - MONGO_PORT=27017
      - MONGO_USER=root
      - MONGO_PASSWORD=admin
    ports:
      - "8000:8000"
    depends_on:
      - mongodb
    volumes:
      - ./models:/opt/spark/models:rw
      - ./spark/spark_apps:/app
volumes:
  spark-logs:
